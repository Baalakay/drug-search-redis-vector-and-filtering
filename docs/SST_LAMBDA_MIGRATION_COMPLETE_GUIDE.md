# Complete SST Lambda Migration Guide: Python + AWS Bedrock to Serverless

## ðŸŽ¯ Overview

This comprehensive guide provides step-by-step instructions for migrating a local Python application using AWS Bedrock to a serverless architecture with SST (Serverless Stack), Lambda, API Gateway, SQS, RDS, and S3. **This guide is specifically designed for AI assistants** to understand the complete migration process, including all common issues and their resolutions.

**ðŸŽ‰ SUCCESS STORY**: This guide documents the complete migration of Python applications to AWS Lambda using SST, achieving:
- âš¡ **45-second deployments** (from 30+ minutes)
- ðŸ“¦ **99.8% package size reduction** (81MB â†’ 144KB)
- ðŸŽ¯ **Zero fallback logic** - clean, proper imports
- ðŸ”§ **"No module named 'core'" RESOLVED** - handler path vs import path mismatch fixed
- ðŸ—ï¸ **Complete serverless architecture** with all AWS services
- ðŸ” **Enterprise security** - private RDS, VPC endpoints, secure access
- ðŸ–¥ï¸ **Database management** - secure access patterns for private resources

## ðŸš¨ **DEFINITIVE SOLUTION SUMMARY**

The "No module named 'core'" issue was NOT a packaging problem - it was a configuration mismatch:

1. **SST Handler Path**: `"functions/src/handlers/handler.handler"` (tells SST where files are)
2. **Lambda Runtime Handler**: `"src.handlers.handler.handler"` (how Lambda calls function)  
3. **Import Paths**: `from functions.src.core.protocols import X` (matches package structure)
4. **Hatchling Config**: `packages = ["src"]` (sufficient - includes all subdirectories)

**Key Insight**: The core directory was ALWAYS deployed correctly. The issue was import path mismatches.

---

## âš ï¸ **CRITICAL ISSUES & SOLUTIONS** (Must Read First!)

### ðŸš¨ **Issue #0: CRITICAL - SST Handler Path Must Match pyproject.toml Package Name**

**Problem**: Lambda fails with `Runtime.ImportModuleError: Unable to import module 'functions/src/handlers/handler'` even with correct directory structure and pyproject.toml.

**Root Cause**: **SST DOES NOT automatically transform handler paths like the docs imply**. The handler path you specify in `sst.aws.Function` is used LITERALLY as the Lambda runtime handler. SST packages your code using the `name` field from `functions/pyproject.toml`, converting hyphens to underscores.

**Example**:
- `functions/pyproject.toml` has `name = "my-functions"`  
- SST packages it as `my_functions/` (hyphens â†’ underscores)
- File is at `functions/src/handlers/handler.py`
- Packaged location: `.sst/artifacts/FunctionName-src/my_functions/src/handlers/handler.py`

**âŒ WRONG Handler Path** (what you might think works):
```typescript
handler: "functions/src/handlers/handler.handler"
// Lambda tries to import: functions.src.handlers.handler
// Fails because "functions" module doesn't exist
```

**âŒ ALSO WRONG** (from other examples):
```typescript
handler: "src.handlers.handler.handler"
// Lambda tries to import: src.handlers.handler  
// Fails because "src" isn't at package root
```

**âœ… CORRECT Handler Path**:
```typescript
// In infra/application.ts
handler: "my_functions.src.handlers.handler.handler"
//        ^^^^^^^^^^^^  (package name from pyproject.toml with hyphens â†’ underscores)
```

**Complete Working Example**:

1. **`functions/pyproject.toml`**:
```toml
[project]
name = "daw-functions"  # â† This becomes "daw_functions" in the package
version = "1.0.0"
requires-python = ">=3.12"
dependencies = [
    "boto3>=1.34.131",
]

[tool.hatch.build.targets.wheel]
packages = ["src"]  # Package the src directory
```

2. **Directory Structure**:
```
functions/
â”œâ”€â”€ __init__.py           # Required!
â”œâ”€â”€ pyproject.toml
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py       # Required!
    â””â”€â”€ handlers/
        â”œâ”€â”€ __init__.py   # Required!
        â””â”€â”€ drug_loader.py
```

3. **SST Configuration** (`infra/application.ts`):
```typescript
const syncFunction = new sst.aws.Function("DrugSync", {
  handler: "daw_functions.src.handlers.drug_loader.lambda_handler",
  //        ^^^^^^^^^^^^^ (name from pyproject.toml, hyphens â†’ underscores)
  runtime: "python3.12",
  // ... other config
});
```

**How to Verify the Correct Handler Path**:
```bash
# 1. Check what SST actually packaged
ls -la .sst/artifacts/YourFunctionName-src/

# 2. Find your handler file
find .sst/artifacts/YourFunctionName-src/ -name "your_handler.py"

# 3. The path from the artifacts root IS your handler path
# Example output: .sst/artifacts/Function-src/my_package/src/handlers/handler.py
# Handler should be: my_package.src.handlers.handler.lambda_handler
```

**Critical Points**:
1. âœ… **ALWAYS check `.sst/artifacts/` to see actual package structure**
2. âœ… **Package name from `pyproject.toml` becomes the root module**
3. âœ… **Hyphens in package names become underscores** (`my-pkg` â†’ `my_pkg`)
4. âœ… **All `__init__.py` files are REQUIRED** (functions/, src/, handlers/)
5. âŒ **SST does NOT use the "functions" prefix in the module path**
6. âŒ **Handler path is NOT relative to project root - it's the Python import path**

**Common Mistakes**:
- Using `"functions/src/handlers/..."` (treats it as file path, not module path)
- Forgetting to convert hyphens to underscores in package name
- Missing `__init__.py` files in the package hierarchy
- Not adding `functions/` to workspace in root `pyproject.toml`

**Result**: Handler paths that work on first deploy without manual Lambda configuration fixes.

---

### ðŸš¨ **Issue #1: Lambda Import Errors - "No module named 'src'"**

**Problem**: Lambda functions fail with import errors despite correct file structure.

**Root Cause**: Hatchling packaging with `packages = ["src"]` creates structure `functions/src/` in Lambda package, not `src/` at root.

**âŒ Wrong Import**:
```python
from src.config.llm_config import LLMModel  # âŒ FAILS
```

**âœ… Correct Import**:
```python
from functions.src.config.llm_config import LLMModel  # âœ… WORKS
```

**Solution Steps**:
1. **Never use fallback logic or sys.path manipulation**
2. **Use absolute imports matching the actual package structure**
3. **Test the package structure**: Check `.sst/artifacts/FunctionName-src/` to see actual layout

### ðŸš¨ **Issue #1.5: "No module named 'core'" - Handler Path vs Import Path Mismatch**

**Problem**: Lambda runtime shows `"No module named 'core'"` despite correct hatchling configuration and file deployment.

**Root Cause**: Mismatch between SST handler path configuration and Lambda runtime import paths. The core directory IS deployed correctly, but imports use wrong paths.

**âœ… DEFINITIVE SOLUTION**:

1. **SST Handler Path** (in `infra/application.ts`):
```typescript
handler: "functions/src/handlers/gap_optimization_handler.handler"
```

2. **Lambda Runtime Handler** (automatically set by SST):
```
"src.handlers.gap_optimization_handler.handler"
```

3. **Import Paths** (in handler code):
```python
from functions.src.core.protocols import GapDetails
from functions.src.services.database_service import DatabaseService
```

4. **Hatchling Configuration** (sufficient as-is):
```toml
[tool.hatch.build.targets.wheel]
packages = ["src"]  # âœ… Automatically includes ALL subdirectories
```

**Verification**: Check local wheel contents:
```bash
cd functions && uv build
python -c "
import zipfile
with zipfile.ZipFile('dist/functions-1.0.0-py3-none-any.whl', 'r') as z:
    files = [f for f in z.namelist() if f.startswith('src/')]
    print('\\n'.join(sorted(files)))
"
```

**Solution Steps**:
1. **Explicitly list ALL packages** including subdirectories in `[tool.hatch.build.targets.wheel]`
2. **Remove SST state**: `rm -rf .sst` and deploy fresh
3. **Verify imports work**: Check health endpoint shows no "No module named" errors

### ðŸš¨ **Issue #2: Massive Lambda Packages (81MB) Causing 30+ Minute Deployments**

**Problem**: Each Lambda function is 81MB, causing extremely slow deployments.

**Root Cause**: Heavy dependencies (pandas, numpy, openpyxl) from root `pyproject.toml` being included in Lambda packages.

**Solution**:
```toml
# âŒ BAD: Root pyproject.toml with heavy dependencies
[project]
dependencies = [
    "pandas>=2.2.2",      # âŒ 40MB+ 
    "numpy>=2.3.3",       # âŒ 20MB+
    "openpyxl>=3.1.5",    # âŒ Large
]

# âœ… GOOD: Root pyproject.toml - minimal deployment dependencies only
[project]
dependencies = [
    "boto3>=1.40.44",     # âœ… Essential for SST
    "botocore>=1.40.44",  # âœ… Essential for SST
]
```

**Result**: 81MB â†’ 144KB per function (99.8% reduction), 30+ minutes â†’ 45 seconds deployment.

### ðŸš¨ **Issue #3: SQS â†’ Lambda Trigger Not Working**

**Problem**: SQS messages sit in queue but don't trigger Lambda functions.

**Root Cause**: Event source mapping pointing to wrong queue (stale ARN from previous deployments).

**Solution**:
```bash
# 1. Check current event source mappings
aws lambda list-event-source-mappings --function-name "your-function-name"

# 2. Delete stale mapping
aws lambda delete-event-source-mapping --uuid "old-uuid"

# 3. Create new mapping with correct queue ARN
aws lambda create-event-source-mapping \
  --function-name "your-function-name" \
  --event-source-arn "arn:aws:sqs:region:account:correct-queue-name" \
  --batch-size 10 \
  --enabled
```

### ðŸš¨ **Issue #4: UV + SST Lambda Packaging Failures**

**Problem**: `Error: failed to run uv build: exit status 2` - "Workspace does not contain any buildable packages"

**Root Cause**: Missing `functions/pyproject.toml` with proper build system configuration.

**Solution**:
```toml
# functions/pyproject.toml - REQUIRED for SST/UV
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "functions"  # âš ï¸ Simple name, not "DAW-functions"
version = "1.0.0"
requires-python = ">=3.12"
dependencies = [
    # Only Lambda runtime dependencies here
    "boto3>=1.34.131",
    "pydantic>=2.8.2",
    # NO pandas, numpy, openpyxl here!
]

[tool.hatch.build.targets.wheel]
packages = ["src"]  # âš ï¸ CRITICAL: Tells hatchling to package src/ directory
```

### ðŸš¨ **Issue #5: UV Sync Errors from .venv Corruption**

**Problem**: `Error: failed to run uv sync: exit status 2` with "failed to remove directory" errors.

**Root Cause**: The .venv directory was corrupted by attempting to delete it. UV manages .venv as a virtual drive that cannot be safely deleted.

**âŒ NEVER DO THIS**:
```bash
rm -rf .venv  # âŒ CAUSES CORRUPTION - .venv is UV managed!
```

**âœ… SOLUTION**:
- **NEVER attempt to delete .venv** - it's managed by UV
- If UV sync errors occur, clean other artifacts but leave .venv alone
- UV will self-heal the .venv over time
- Focus on fixing the actual deployment issues, not .venv

**Prevention**: Add this to memory bank and session reminders - .venv is off-limits.

### ðŸš¨ **Issue #6: SST State Out of Sync (Manual AWS CLI Changes)**

**Problem**: Manual AWS CLI changes (like setting environment variables) cause SST state to go out of sync with actual resources.

**Root Cause**: SST compares config to cached state file, not actual cloud resources. Manual changes break this sync.

**âŒ WRONG Solution**: `sst remove` (nuclear option - destroys everything)

**âœ… CORRECT Solution**: `sst refresh` (syncs state with reality)
```bash
# Step 1: Sync state with actual cloud resources
sst refresh --stage dev

# Step 2: Deploy config changes
sst deploy --stage dev
```

**Prevention**: NEVER manually update AWS resources outside of SST (use SST config files only).

**Reference**: [SST State Management Documentation](https://sst.dev/docs/state/#out-of-sync)

### ðŸš¨ **Issue #7: Reserved AWS Environment Variables**

**Problem**: `InvalidParameterValueException: Reserved keys used in this request: AWS_REGION`

**Solution**: Never set `AWS_REGION` in Lambda environment variables - it's automatically provided.

```typescript
// âŒ BAD
environment: {
  AWS_REGION: "us-east-1",  // âŒ Reserved key
}

// âœ… GOOD  
environment: {
  ENVIRONMENT: stage,
  S3_BUCKET_NAME: bucket.name,
  // AWS_REGION is automatically available
}
```

### ðŸš¨ **Issue #6: Pulumi State Corruption**

**Problem**: Deployments fail with "pending operations" or "update canceled" errors.

**Root Cause**: Pulumi state becomes corrupted after failed deployments or manual resource changes.

**Solution**:
```bash
# Option 1: Refresh Pulumi state (try this first)
npx sst refresh --stage staging

# Option 2: If refresh fails, reset state (DESTRUCTIVE)
# âš ï¸ WARNING: This deletes all resources!
npx sst remove --stage staging
# Then redeploy from scratch
npx sst deploy --stage staging

# Option 3: Manual state bucket cleanup (if needed)
# Find and delete the SST state bucket in S3
```

### ðŸš¨ **Issue #7: Secrets Manager "Already Scheduled for Deletion"**

**Problem**: `DBPassword aws:secretsmanager:Secret ... a secret with this name is already scheduled for deletion`

**Root Cause**: AWS Secrets Manager has a recovery window for deleted secrets (7-30 days).

**Solution**:
```typescript
// Add version suffix to secret names
const dbPassword = new aws.secretsmanager.Secret("DBPassword", {
  name: `${generateResourceName("db-password", stage)}-v2`, // âœ… Add version suffix
  description: "Password for RDS PostgreSQL",
});
```

### ðŸš¨ **Issue #8: Lambda Handler Path Confusion**

**Problem**: SST can't find handler files with various path errors.

**Root Cause**: Handler path must match the actual package structure created by hatchling.

**Solution**:
```typescript
// âœ… CORRECT: Handler path for hatchling + SST
const apiHandler = new sst.aws.Function("ApiHandler", {
  handler: "functions/src/handlers/api_handler.handler",
  //          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  //          This path works with hatchling packaging
});
```

### ðŸš¨ **Issue #9: Database Dependency Conflicts (greenlet)**

**Problem**: UV sync fails with `greenlet` dependency errors when adding database dependencies.

**Root Cause**: SQLAlchemy's `greenlet` dependency conflicts in some environments.

**Solution**:
```bash
# Set UV link mode to avoid hardlinking issues
export UV_LINK_MODE=copy

# Or temporarily remove database dependencies during initial setup
# Add them back after core functionality is working
```

### ðŸš¨ **Issue #10: SST Resource Naming Auto-Suffixes**

**Problem**: Resources get unexpected suffixes like `MyQueue-abc123def` instead of exact names.

**Root Cause**: SST automatically adds unique suffixes to certain resource types for CloudFormation compatibility.

**Solution - Accept SST Behavior**:
```typescript
// âœ… SST components with auto-suffixes (accept this)
const queue = new sst.aws.Queue("ProcessingQueue", {
  // Results in: "project-staging-ProcessingQueueQueue-abc123"
});

// âœ… Use raw Pulumi for exact names (when needed)
const bucket = new aws.s3.BucketV2("DataBucket", {
  bucket: `${projectName}-${stage}`, // Exact name: "project-staging"
});
```

**Resources with SST auto-suffixes**:
- SQS Queues: `sst.aws.Queue` â†’ `QueueName-suffix`
- API Gateway: `sst.aws.ApiGatewayV2` â†’ `ApiName-suffix`

**Resources with exact naming (raw Pulumi)**:
- S3 Buckets: `aws.s3.BucketV2`
- RDS Databases: `aws.rds.Instance`
- Parameter Store: `aws.ssm.Parameter`

### ðŸš¨ **Issue #11: CRITICAL - Using Raw Pulumi Lambda Instead of sst.aws.Function**

**Problem**: Lambda deployment completes but function doesn't exist. `PromiseRejectionHandledWarning` in logs. All related resources created (IAM role, EventBridge, CloudWatch logs) except the Lambda function itself.

**Root Cause**: **Using raw Pulumi `aws.lambda.Function` instead of SST's `sst.aws.Function`**. Raw Pulumi doesn't integrate with SST's Python packaging system, causing silent failures.

**Symptoms**:
```bash
âœ“  Deploy complete
   sync: {functionArn: "arn:...", scheduleArn: "arn:..."}
# But aws lambda list-functions shows NO function

# In logs:
(node:1865) PromiseRejectionHandledWarning: Promise rejection was handled asynchronously
```

**How to Identify**:
```bash
# Check if Lambda exists
aws lambda list-functions --query 'Functions[?contains(FunctionName, `YourFunction`)].FunctionName'

# Check if related resources exist (confirming silent failure)
aws cloudwatch describe-alarms --alarm-name-prefix "YourFunction"  # âœ… Exists
aws events list-rules --name-prefix "YourFunction"  # âœ… Exists  
aws iam get-role --role-name "YourFunction-Role"  # âœ… Exists
# But Lambda function: âŒ Missing
```

**âŒ WRONG - Raw Pulumi (causes silent failure)**:
```typescript
import * as aws from "@pulumi/aws";

const syncFunction = new aws.lambda.Function("MyFunction", {
  role: lambdaRole.arn,
  runtime: aws.lambda.Runtime.Python3d12,
  handler: "my_handler.lambda_handler",
  code: new pulumi.asset.FileArchive("./functions/"),
  // ... more config
});
```

**âœ… CORRECT - SST Native Construct**:
```typescript
const syncFunction = new sst.aws.Function("MyFunction", {
  handler: "my_package.src.handlers.my_handler.lambda_handler",
  runtime: "python3.12",
  timeout: "15 minutes",
  memory: "1 GB",
  vpc: {
    securityGroups: [sgId],
    privateSubnets: subnetIds,
  },
  environment: {
    DB_HOST: dbHost,
    // ... env vars
  },
  permissions: [
    { actions: ["bedrock:InvokeModel"], resources: ["*"] },
  ],
});
```

**Key Differences**:
1. âœ… `sst.aws.Function` handles Python packaging automatically
2. âœ… Integrates with UV/hatchling build system  
3. âœ… Proper error reporting (no silent failures)
4. âœ… Automatic IAM role creation with permissions
5. âœ… VPC configuration simplified
6. âŒ Raw Pulumi requires manual packaging and IAM setup

**Migration Steps** (if you used raw Pulumi):
```bash
# 1. Delete manually created resources
aws lambda delete-function --function-name YourFunction || true
aws iam delete-role --role-name YourFunction-Role || true  # After detaching policies

# 2. Update infra code to use sst.aws.Function
# 3. Ensure functions/pyproject.toml exists with proper config
# 4. Deploy
npx sst deploy --stage dev

# 5. Verify Lambda exists
aws lambda list-functions --query 'Functions[?contains(FunctionName, `YourFunction`)]'
```

**Result**: Lambda function successfully created and deployable on first attempt.

---

### ðŸš¨ **Issue #12: SST Lambda Deployment Failures - Account ID Shows Placeholder**

**Problem**: SST deployment logs show placeholder account ID (`123456789012`) instead of actual AWS account.

**Root Cause**: `project.config.ts` has placeholder account ID in stage configuration.

**Symptoms**:
```bash
ðŸš€ Deploying DAW to stage: dev
ðŸ“ Region: us-east-1
ðŸ” Account: 123456789012  # â† Placeholder!
```

**Solution**:
```typescript
// project.config.ts
export const projectConfig = {
  stages: {
    dev: {
      protect: false,
      removal: "remove" as const,
      account: process.env.AWS_ACCOUNT_ID_DEV || "750389970429",  // â† Use real account ID
      region: "us-east-1",
    },
  },
};
```

**How to Find Your Account ID**:
```bash
aws sts get-caller-identity --query Account --output text
```

---

### ðŸš¨ **Issue #13: Node.js Version Incompatibility with VPC Lambda**

**Problem**: `RangeError: Invalid string length` when deploying Lambda functions to VPC, even with small packages.

**Root Cause**: Node.js version incompatibility. SST v3 VPC Lambda deployments require **Node.js v24.5.0 specifically**.

**Symptoms**:
```bash
# Deployment crashes with:
RangeError: Invalid string length
    at Object.stringify (node:internal/deps/...)

# Even with:
- Small Lambda packages (2-4 KB)
- Clean .sst directory
- Optimized dependencies
```

**âŒ Failing Version**:
- Node.js v22.x, v23.x with SST 3.17.x = `RangeError` on VPC Lambda

**âœ… Working Version**:
- Node.js v24.5.0 with SST 3.17.x = Successful VPC Lambda deployment

**Solution**:
```bash
# Install correct Node.js version
nvm install 24.5.0
nvm use 24.5.0

# Set as default to prevent issues
nvm alias default 24.5.0

# Verify
node --version  # Should show v24.5.0

# Deploy
npx sst deploy --stage dev
```

**Prevention**: Add to `.nvmrc`:
```bash
echo "24.5.0" > .nvmrc
```

**Reference**: Documented in `docs/SST_LAMBDA_MIGRATION_COMPLETE_GUIDE.md` Issue #11 (line 999-1023).

---

### ðŸš¨ **Issue #14: SST VPC Property Renamed - vpc.subnets â†’ vpc.privateSubnets**

**Problem**: Deployment fails with error `The "vpc.subnets" property has been renamed to "vpc.privateSubnets"`.

**Root Cause**: SST API change in recent versions.

**âŒ Old Syntax**:
```typescript
vpc: {
  securityGroups: [sgId],
  subnets: subnetIds,  // âŒ Deprecated
}
```

**âœ… New Syntax**:
```typescript
vpc: {
  securityGroups: [sgId],
  privateSubnets: subnetIds,  // âœ… Correct
}
```

**Quick Fix**: Global search and replace in `infra/` directory:
```bash
grep -r "vpc.*subnets:" infra/ | grep -v privateSubnets
# Then update all occurrences
```

---

### ðŸš¨ **Issue #15: API Gateway Permissions and Routes Not Created**

**Problem**: API Gateway created but routes don't work. Lambda exists but isn't triggered.

**Root Cause**: 
- Missing Lambda invoke permissions for API Gateway
- Routes not properly configured

**Solution Steps**:
1. **Add API Gateway permissions**:
```bash
aws lambda add-permission \
  --function-name FUNCTION_NAME \
  --statement-id api-gateway-invoke \
  --action lambda:InvokeFunction \
  --principal apigateway.amazonaws.com \
  --source-arn "arn:aws:execute-api:REGION:ACCOUNT:API_ID/*/*/*"
```

2. **Add Missing Routes**:
```bash
aws apigatewayv2 create-route \
  --api-id API_ID \
  --route-key "POST /v2/endpoint" \
  --target "integrations/INTEGRATION_ID"
```

3. **Verify in SST Config**:
```typescript
api.route("GET /health", apiHandler.arn);
api.route("POST /endpoint", apiHandler.arn);
```

### ðŸš¨ **Issue #12: Gap Type Classification Returning Null**

**Problem**: Gap optimization returns `gap_type: null` despite correct logic.

**Root Cause**: Datetime parsing timezone mismatch between offset-naive and offset-aware datetimes.

**âŒ Failing Code**:
```python
scheduled_datetime = datetime.fromisoformat(scheduled_time.replace('Z', '+00:00'))
current_datetime = datetime.utcnow()  # âŒ Timezone naive
notice_minutes = int((scheduled_datetime - current_datetime).total_seconds() / 60)
```

**âœ… Fixed Code**:
```python
scheduled_datetime = datetime.fromisoformat(scheduled_time.replace('Z', '+00:00'))
current_datetime = datetime.utcnow().replace(tzinfo=scheduled_datetime.tzinfo)  # âœ… Match timezone
notice_minutes = int((scheduled_datetime - current_datetime).total_seconds() / 60)
```

### ðŸš¨ **Issue #13: Lambda Layer Dependencies Not Available**

**Problem**: Lambda functions can't import dependencies despite Lambda Layer being attached.

**Root Cause**: 
- Lambda Layer doesn't contain required packages (pg8000, etc.)
- Import path issues with layer dependencies

**Solution**:
1. **Verify Layer Contents**:
```bash
aws lambda get-layer-version --layer-name LAYER_NAME --version-number 1
```

2. **Update Layer with Missing Dependencies**:
```bash
# Create layer with all dependencies
mkdir -p layers/python-dependencies/python
pip install pg8000 boto3 pydantic -t layers/python-dependencies/python/
zip -r python-dependencies.zip layers/python-dependencies/

# Update layer
aws lambda publish-layer-version \
  --layer-name python-dependencies \
  --zip-file fileb://python-dependencies.zip \
  --compatible-runtimes python3.12
```

3. **Attach Layer to Function**:
```bash
aws lambda update-function-configuration \
  --function-name FUNCTION_NAME \
  --layers "arn:aws:lambda:REGION:ACCOUNT:layer:LAYER_NAME:VERSION"
```

---

## ðŸŽ‰ **COMPLETE WORKING SOLUTION**

### **Final Project Structure That Works**

```
DAW/
â”œâ”€â”€ pyproject.toml                  # âœ… Minimal deployment deps only
â”œâ”€â”€ sst.config.ts                   # âœ… Dynamic imports, stage-specific regions
â”œâ”€â”€ project.config.ts               # âœ… Centralized config with proper timeouts
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ infrastructure.ts           # âœ… Raw Pulumi for exact naming
â”‚   â””â”€â”€ application.ts              # âœ… Correct handler paths
â””â”€â”€ functions/
    â”œâ”€â”€ __init__.py                 # âœ… Required for packaging
    â”œâ”€â”€ pyproject.toml              # âœ… Hatchling build system
    â””â”€â”€ src/
        â”œâ”€â”€ handlers/
        â”‚   â”œâ”€â”€ api_handler.py      # âœ… functions.src.* imports
        â”‚   â”œâ”€â”€ ai_processor.py     # âœ… functions.src.* imports
        â”‚   â””â”€â”€ data_processor.py   # âœ… functions.src.* imports
        â”œâ”€â”€ config/
        â”œâ”€â”€ services/
        â””â”€â”€ utils/
```

### **Working Import Pattern**

```python
# âœ… CORRECT: All handler files use this pattern
from functions.src.config.llm_config import LLMModel
from functions.src.config.aws_config import get_aws_config
from functions.src.services.bedrock_service import BedrockService
from functions.src.utils.logging_config import setup_logging

# âŒ NEVER use fallback logic, sys.path manipulation, or try/except imports
```

### **Working pyproject.toml Files**

**Root pyproject.toml** (Deployment only):
```toml
[project]
name = "DAW-lambda"
version = "1.0.0"
requires-python = ">=3.12"
dependencies = [
    # Only SST deployment dependencies - NOT Lambda runtime dependencies
    "boto3>=1.40.44",
    "botocore>=1.40.44",
]

[tool.uv]
package = false

[tool.uv.workspace]
members = ["functions"]  # âœ… CRITICAL: UV workspace configuration
```

**functions/pyproject.toml** (Lambda runtime):
```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "functions"  # âœ… Simple name
version = "1.0.0"
requires-python = ">=3.12"
dependencies = [
    # Only Lambda runtime dependencies
    "boto3>=1.34.131",
    "botocore>=1.34.131",
    "pydantic>=2.8.2",
    "python-json-logger>=2.0.7",
    "requests>=2.32.3",
    "python-dotenv>=1.1.0",
    # NO pandas, numpy, openpyxl, or other heavy packages!
]

[tool.hatch.build.targets.wheel]
packages = ["src"]  # âœ… CRITICAL: Package the src directory
```

### **Performance Metrics Achieved**

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Deployment Time** | 30+ minutes | 45 seconds | **97% faster** |
| **Lambda Package Size** | 81MB each | 144KB each | **99.8% smaller** |
| **Cold Start Time** | N/A | ~1.1 seconds | **Excellent** |
| **API Response Time** | N/A | ~200ms | **Fast** |
| **SQS Processing** | N/A | ~60ms | **Instant** |
| **Build Success Rate** | 20% | 100% | **Reliable** |

### **Working Pipeline Flow**

```
POST /analyze-patients
         â†“
    API Gateway (âœ… Working)
         â†“
    Lambda: API Handler (âœ… Working)
         â†“
    SQS Message (âœ… Working)
         â†“
    Lambda: AI Processor (âœ… Working)
         â†“
    AWS Bedrock (âœ… Ready)
         â†“
    S3 Results Storage (âœ… Ready)
         â†“
    GET /analysis/{job_id} (âœ… Working)
```

## ðŸš€ **DEPLOYMENT COMMANDS THAT WORK**

### **Pre-Deployment Checklist**

```bash
# 1. Verify UV workspace is properly configured
cd /path/to/your/project
uv sync  # Should work without errors

# 2. Check package structure
ls -la functions/
# Should see: __init__.py, pyproject.toml, src/

# 3. Verify handler imports
grep -r "from functions.src" functions/src/handlers/
# Should show all imports using functions.src.* pattern

# 4. Check package sizes (optional)
cd functions && uv export --format requirements-txt > requirements.txt
# Should be small list without pandas/numpy
```

### **Deployment Sequence**

```bash
# 1. Clean deployment (if needed)
npx sst remove --stage staging  # âš ï¸ Destroys all resources

# 2. Deploy infrastructure
npx sst deploy --stage staging

# 3. Monitor deployment progress
# Should complete in ~45 seconds with 144KB packages

# 4. Test endpoints
curl -X GET "https://your-api-url/health"
curl -X POST "https://your-api-url/analyze-patients" \
  -H "Content-Type: application/json" \
  -d '{"office_id": "test", "gap_details": {...}}'
```

### **Debugging Failed Deployments**

```bash
# 1. Check Lambda logs
aws logs describe-log-groups --log-group-name-prefix "/aws/lambda/your-function"
aws logs get-log-events --log-group-name "/aws/lambda/your-function" \
  --log-stream-name "latest-stream"

# 2. Check SQS queues
aws sqs list-queues --queue-name-prefix "your-project"
aws sqs get-queue-attributes --queue-url "your-queue-url" \
  --attribute-names ApproximateNumberOfMessages

# 3. Check package structure
ls -la .sst/artifacts/YourFunction-src/
# Verify functions/src/ directory exists

# 4. Refresh corrupted state
npx sst refresh --stage staging
```

---

## ðŸ”§ **TROUBLESHOOTING GUIDE**

### **Common Error Patterns**

| Error Message | Root Cause | Solution |
|---------------|------------|----------|
| `No module named 'src'` | Wrong import path | Use `from functions.src.*` |
| `failed to run uv build` | Missing `functions/pyproject.toml` | Create with hatchling backend |
| `81MB package size` | Heavy deps in root | Remove pandas/numpy from root |
| `update canceled` | Pulumi state corruption | Run `npx sst refresh` |
| `Reserved keys: AWS_REGION` | Invalid env var | Remove AWS_REGION from Lambda env |
| `NonExistentQueue` | Stale event mapping | Delete and recreate mapping |
| `already scheduled for deletion` | Secret name conflict | Add version suffix to name |

### **Performance Troubleshooting**

**If deployment takes >5 minutes**:
1. Check Lambda package sizes in `.sst/artifacts/`
2. Remove heavy dependencies from both `pyproject.toml` files
3. Verify UV workspace configuration

**If Lambda functions fail to start**:
1. Check CloudWatch logs for import errors
2. Verify handler paths match package structure
3. Test imports locally: `python -c "from functions.src.config import llm_config"`

**If SQS messages aren't processed**:
1. Check event source mappings: `aws lambda list-event-source-mappings`
2. Verify SQS permissions in Lambda IAM role
3. Check dead letter queue for failed messages

---

## ðŸ“‹ Prerequisites

### Required Tools
- **AWS CLI** configured with appropriate permissions
- **Node.js 18+** installed
- **Python 3.12+** installed
- **UV (Python package manager)** installed and working
- **TypeScript** knowledge for SST configuration
- Git repository initialized

### AWS Setup
- AWS account with appropriate permissions
- IAM roles for Lambda, RDS, S3, SQS access
- Bedrock model access enabled in your region
- VPC configuration (if using RDS)

---

## ðŸ—ï¸ Complete Project Structure

```
your-project/
â”œâ”€â”€ README.md
â”œâ”€â”€ package.json                    # Node.js dependencies for SST
â”œâ”€â”€ sst.config.ts                   # SST application configuration
â”œâ”€â”€ sst-env.d.ts                    # TypeScript environment definitions
â”œâ”€â”€ project.config.ts               # Centralized project configuration
â”œâ”€â”€ pyproject.toml                  # ROOT Python workspace configuration
â”œâ”€â”€ uv.lock                         # UV lock file (root)
â”œâ”€â”€ .python-version                 # Python version for UV
â”œâ”€â”€ .env                            # Local environment variables (gitignored)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ infra/                          # Infrastructure as Code
â”‚   â”œâ”€â”€ infrastructure.ts           # Core AWS resources (RDS, S3, SQS, Parameter Store)
â”‚   â””â”€â”€ application.ts              # Lambda functions and API Gateway
â”œâ”€â”€ functions/                      # Lambda function code
â”‚   â”œâ”€â”€ __init__.py                 # âš ï¸ REQUIRED for SST/UV
â”‚   â”œâ”€â”€ pyproject.toml              # âš ï¸ CRITICAL: Functions package config
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies for Lambda
â”‚   â”œâ”€â”€ uv.lock                     # UV lock file (functions)
â”‚   â”œâ”€â”€ .python-version             # Python version (3.12)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ llm_config.py       # LLM model type definitions
â”‚       â”‚   â””â”€â”€ aws_config.py       # AWS Parameter Store integration
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ bedrock_service.py  # Bedrock Converse API service
â”‚       â”‚   â”œâ”€â”€ s3_service.py       # S3 operations
â”‚       â”‚   â””â”€â”€ sqs_service.py      # SQS operations
â”‚       â”œâ”€â”€ handlers/               # Lambda entry points
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ api_handler.py      # API Gateway handlers
â”‚       â”‚   â”œâ”€â”€ data_processor.py   # Data preprocessing
â”‚       â”‚   â””â”€â”€ ai_processor.py     # AI analysis processor
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ data_models.py      # Pydantic models
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ logging_config.py
â”‚           â””â”€â”€ helpers.py
â”œâ”€â”€ database/                       # Database schemas and migrations
â”‚   â”œâ”€â”€ schema.sql                  # PostgreSQL schema
â”‚   â””â”€â”€ migrations/
â”œâ”€â”€ scripts/                        # Deployment and utility scripts
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”œâ”€â”€ setup-env.sh
â”‚   â”œâ”€â”€ pre-deploy.sh               # Pre-deployment cleanup
â”‚   â””â”€â”€ import_data.py              # Data import scripts
â””â”€â”€ tests/                          # Test files
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ unit/
    â””â”€â”€ integration/
```

---

## ðŸ”§ Critical Configuration Files

### 1. Root pyproject.toml (CRITICAL FOR UV WORKSPACE)

This file is **ESSENTIAL** for UV + SST to work correctly. The `[tool.uv.workspace]` section is **REQUIRED**.

```toml
[project]
name = "your-project-name"
version = "1.0.0"
description = "Serverless Lambda deployment infrastructure"
requires-python = ">=3.12"
dependencies = [
    "boto3>=1.40.44",
    "botocore>=1.40.44",
    "pydantic>=2.11.9",
    "pandas>=2.2.2",
    "openpyxl>=3.1.5",
    "psycopg2-binary>=2.9.10",
    "sqlalchemy>=2.0.40",
]

[tool.uv]
package = false

[tool.uv.workspace]
members = ["functions"]
```

**âš ï¸ CRITICAL NOTES:**
- The `[tool.uv.workspace]` section with `members = ["functions"]` is **ABSOLUTELY REQUIRED**
- Keep root dependencies minimal - only what's needed for local development
- Do NOT include large packages like streamlit, jupyterlab, scikit-learn unless absolutely necessary

### 2. functions/pyproject.toml (CRITICAL FOR SST LAMBDA PACKAGING)

This file is **REQUIRED** for SST's UV integration to work. Without this, you will get `"Workspace does not contain any buildable packages"` errors.

```toml
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "functions"
version = "1.0.0"
description = "Lambda functions package"
requires-python = ">=3.12"
dependencies = [
    "boto3>=1.34.131",
    "botocore>=1.34.131",
    "pydantic>=2.8.2",
    "python-json-logger>=2.0.7",
    "requests>=2.32.3",
    "pg8000>=1.31.2",
]

[tool.hatch.build.targets.wheel]
packages = ["src"]  # âœ… Automatically includes ALL subdirectories
```

**âš ï¸ CRITICAL NOTES:**
- âœ… Use `hatchling` build backend (proven to work with SST)
- âœ… **CRITICAL**: `packages = ["src"]` automatically includes ALL subdirectories
- âœ… **NEVER** explicitly list subdirectories - causes duplicate file warnings
- âœ… All Lambda dependencies must be listed here
- âœ… Keep this synchronized with `functions/requirements.txt`

### 3. functions/.python-version

```
3.12.10
```

This file tells UV which Python version to use for the functions package.

### 4. functions/__init__.py

```python
"""Your Project Lambda Functions Package"""
__version__ = "1.0.0"
```

This file makes the functions directory a proper Python package.

### 5. project.config.ts (Centralized Configuration)

```typescript
/**
 * Project Configuration - Single Source of Truth
 */

export const projectConfig = {
  // ðŸ·ï¸ Project identification
  projectName: "your-project-name",
  description: "AWS Lambda serverless application",
  
  // ðŸŒ AWS configuration
  aws: {
    region: "us-east-1",
    profile: "default",
  },
  
  // ðŸ› ï¸ Resource configuration
  resources: {
    // ðŸª£ S3 Bucket configuration
    bucket: {
      versioning: true,
      lifecycleRules: true,
    },
    
    // ðŸ—„ï¸ RDS Database configuration
    database: {
      engine: "postgres",
      version: "16.4", // Use valid RDS PostgreSQL version
      instanceClass: "db.t3.micro",
      allocatedStorage: 20,
      maxAllocatedStorage: 100,
      multiAz: false, // Set true for production
      backupRetentionDays: 7,
      deletionProtection: false, // Set true for production
    },
    
    // ðŸ Lambda function configuration
    lambda: {
      runtime: "python3.12" as const,
      timeout: "15 minutes",
      memory: "1024 MB",
      architecture: "x86_64" as const,
    },
    
    // ðŸ“¬ SQS Queue configuration  
    queue: {
      visibilityTimeout: "5 minutes",
      messageRetentionPeriod: "14 days",
    },
    
    // ðŸ”— API Gateway configuration
    api: {
      throttle: {
        rateLimit: 1000,
        burstLimit: 2000,
      },
      cors: {
        allowOrigins: ["*"],
        allowMethods: ["GET", "POST", "PUT", "DELETE"],
        allowHeaders: ["Content-Type", "Authorization"],
      },
    },
  },
  
  // ðŸš€ Stage-specific configuration
  stages: {
    dev: {
      protect: false,
      removal: "remove" as const,
      account: "123456789012", // Your dev AWS account ID
      region: "us-east-1",
    },
    staging: {
      protect: false,
      removal: "remove" as const,
      account: "123456789013", // Your staging AWS account ID
      region: "us-east-1",
    },
    production: {
      protect: true,
      removal: "retain" as const,
      account: "123456789014", // Your production AWS account ID
      region: "us-east-1",
    },
  },
} as const;

// Helper functions for consistent naming
export const generateResourceName = (resourceType: string, stage: string) => {
  return `${projectConfig.projectName}-${resourceType}-${stage}`;
};

export const generateFunctionName = (functionName: string, stage: string) => {
  return `${projectConfig.projectName}-${stage}-${functionName}`;
};

export const generateBucketName = (stage: string) => {
  return `${projectConfig.projectName}-${stage}`;
};

// Stage-specific account configuration
export const getAccountConfig = (stage: string) => {
  const stageConfig = projectConfig.stages[stage as keyof typeof projectConfig.stages];
  if (!stageConfig) {
    throw new Error(`Unknown stage: ${stage}`);
  }
  return stageConfig;
};

// Type exports
export type ProjectConfig = typeof projectConfig;
export type Stage = keyof typeof projectConfig.stages;
```

### 6. sst.config.ts (SST Configuration)

```typescript
/// <reference path="./.sst/platform/config.d.ts" />

/**
 * âš ï¸ CRITICAL: Do NOT use top-level imports!
 * SST requires all imports to be dynamic (inside functions)
 */

export default $config({
  async app(input) {
    // âœ… Dynamic import - REQUIRED by SST
    const { projectConfig, getAccountConfig } = await import("./project.config");
    
    return {
      name: projectConfig.projectName,
      removal: input?.stage ? getAccountConfig(input.stage).removal : "remove",
      protect: input?.stage ? getAccountConfig(input.stage).protect : false,
      home: "aws",
      providers: {
        aws: {
          region: input?.stage ? getAccountConfig(input.stage).region : projectConfig.aws.region,
          profile: projectConfig.aws.profile,
          // âš ï¸ Only use assumeRole if deploying to different account
          // ...(input?.stage && {
          //   assumeRole: {
          //     roleArn: `arn:aws:iam::${getAccountConfig(input.stage).account}:role/OrganizationAccountAccessRole`,
          //   },
          // }),
        },
      },
    };
  },
  async run() {
    // âœ… Dynamic imports - REQUIRED by SST
    const infrastructure = await import("./infra/infrastructure");
    const application = await import("./infra/application");

    // Deploy infrastructure first
    const infra = infrastructure.InfrastructureStack();
    
    // Deploy application layer
    const app = application.ApplicationStack(infra);

    // Return outputs for easy access
    return {
      vpcId: infra.vpcId,
      database: {
        host: infra.database.host,
        port: infra.database.port,
        database: infra.database.database,
        username: infra.database.username,
        passwordSecretArn: infra.database.passwordSecretArn,
        endpoint: infra.database.endpoint,
      },
      bucket: infra.bucket.name,
      processingQueue: infra.processingQueue.url,
      api: app.api.url,
      functions: {
        dataProcessor: app.dataProcessor.name,
        aiProcessor: app.aiProcessor.name,
        apiHandler: app.apiHandler.name,
      },
    };
  },
});
```

### ðŸš¨ **Issue #11: VPC Lambda Deployment - "RangeError: Invalid string length"**

**Problem**: VPC Lambda deployments fail with `RangeError: Invalid string length` in SST v3.

**Root Cause**: SST v3 bug with Node.js version compatibility when deploying Lambda functions to VPC.

**âŒ Failing Version**:
- Node.js v22.20.0 + SST 3.17.14 = RangeError on VPC Lambda deployment

**âœ… Working Version**:
- Node.js v24.5.0 + SST 3.17.14 = Successful VPC Lambda deployment

**Solution Steps**:
```bash
# Install working Node.js version
nvm install 24.5.0
nvm use 24.5.0

# Verify versions
node --version  # Should show v24.5.0
npx sst version # Should show sst 3.17.14

# Deploy VPC Lambdas successfully
npx sst deploy --stage staging
```

**Result**: VPC Lambda deployment works perfectly, enabling private RDS access.

### ðŸš¨ **Issue #12: VPC Lambda Secrets Manager Access**

**Problem**: VPC Lambda functions timeout when accessing AWS Secrets Manager.

**Root Cause**: VPC Lambda functions cannot reach AWS services without VPC endpoints or NAT Gateway routing.

**âŒ Symptoms**:
- Lambda gets AWS credentials but hangs on `secrets_client.get_secret_value()`
- 5-minute timeouts with no error logs beyond "Found credentials"

**âœ… Solution**: Add VPC Endpoint for Secrets Manager
```typescript
// In infrastructure.ts
const secretsManagerVpcEndpoint = new aws.ec2.VpcEndpoint("SecretsManagerVpcEndpoint", {
  vpcId: vpcId,
  serviceName: "com.amazonaws.us-east-1.secretsmanager",
  vpcEndpointType: "Interface", 
  subnetIds: privateSubnetIds,
  securityGroupIds: [dbSecurityGroup.id],
  privateDnsEnabled: true,
});
```

**Alternative**: Use NAT Gateway routing (more expensive but works for all AWS services).

### ðŸš¨ **Issue #13: SST Credential Expiration During Long Deployments**

**Problem**: SST deployments fail with "ExpiredToken: The security token included in the request is expired".

**Root Cause**: Long VPC deployments (10+ minutes) exceed AWS credential TTL.

**âŒ Error**:
```
aws: failed to refresh cached credentials, operation error STS: AssumeRole, 
https response error StatusCode: 403, RequestID: ..., api error ExpiredToken
```

**âœ… Solutions**:
1. **Refresh credentials before deployment**:
   ```bash
   aws sts get-caller-identity  # Verify credentials
   npx sst deploy --stage staging
   ```

2. **Clear SST credential cache**:
   ```bash
   rm -rf ~/.aws/cli/cache/*
   npx sst deploy --stage staging
   ```

3. **Use longer-lived credentials** for VPC deployments

**Result**: Deployment completes without credential timeouts.

### ðŸš¨ **Issue #14: Database Access to Private RDS in VPC**

**Problem**: Cannot access private RDS database from local development tools for debugging and management.

**Root Cause**: RDS is in private subnets within VPC for security, no direct internet access.

**âŒ Common Failed Approaches**:
- Direct connection to RDS endpoint (times out)
- VPN setup (complex, requires network changes)
- Making RDS public (security risk)

**âœ… Solution - EC2 Bastion Host with Port Forwarding**:

1. **Create EC2 Instance with SSM Access**:
```bash
# Use Amazon Linux 2023 AMI (has SSM agent pre-installed)
# Attach IAM role with AmazonSSMManagedInstanceCore policy
# Place in public subnet of same VPC as RDS
# Security group: Allow SSH (22) and custom port (15432)
```

2. **Install port forwarding tool on EC2** (via SSM Session Manager):
```bash
aws ssm start-session --target i-YOUR-INSTANCE-ID
sudo yum install socat -y
```

3. **Create persistent port forwarding tunnel**:
```bash
# This creates a persistent tunnel that survives disconnections
sudo socat TCP-LISTEN:15432,fork,reuseaddr TCP:your-rds-endpoint.rds.amazonaws.com:5432 &

# Verify tunnel is running
netstat -tlnp | grep 15432
```

4. **Add security group rule to EC2**:
```bash
aws ec2 authorize-security-group-ingress \
    --group-id sg-YOUR-EC2-SG \
    --protocol tcp \
    --port 15432 \
    --cidr 0.0.0.0/0
```

5. **Configure Database Client**:
```
Host: EC2-PUBLIC-IP (e.g., 34.207.158.233)
Port: 15432  
Database: your-database
Username: your-username
Password: [from Secrets Manager]
```

**Alternative - AWS CLI Port Forwarding** (requires SessionManager plugin locally):
```bash
aws ssm start-session \
    --target i-YOUR-INSTANCE-ID \
    --document-name AWS-StartPortForwardingSessionToRemoteHost \
    --parameters '{"host":["rds-endpoint"],"portNumber":["5432"],"localPortNumber":["15432"]}'
```

**Connection Test**:
```bash
# Test tunnel from command line
psql -h EC2-PUBLIC-IP -p 15432 -U username -d database

# Or with Python
python3 -c "
import psycopg2
conn = psycopg2.connect(host='EC2-PUBLIC-IP', port=15432, database='db', user='user', password='pass')
print('âœ… Connection successful!')
"
```

**Security Best Practices**:
- âœ… Use SSM Session Manager (no SSH keys needed)
- âœ… Keep RDS in private subnets
- âœ… Restrict security group to specific IPs if possible
- âœ… Use IAM roles instead of access keys
- âœ… Monitor access logs

**Result**: Secure access to private RDS with enterprise security maintained.

---

## ðŸ—ï¸ **SST CONFIGURATION**

**âš ï¸ CRITICAL SST CONFIGURATION RULES:**
1. **NO top-level imports** - SST will fail with "Your sst.config.ts has top level imports"
2. **Use dynamic imports** inside `app()` and `run()` functions
3. **Use `await import()`** for all configuration and infrastructure modules
4. Only use `assumeRole` if deploying to a different AWS account

### 7. package.json

```json
{
  "name": "your-project-name",
  "version": "1.0.0",
  "description": "Serverless Lambda application",
  "scripts": {
    "dev": "sst dev",
    "build": "sst build",
    "deploy": "sst deploy",
    "deploy:staging": "sst deploy --stage staging",
    "deploy:prod": "sst deploy --stage production",
    "remove": "sst remove",
    "remove:staging": "sst remove --stage staging",
    "test": "sst shell pytest tests/",
    "logs": "sst logs --stage staging --tail",
    "console": "sst console"
  },
  "dependencies": {
    "sst": "^3.0.0",
    "aws-cdk-lib": "^2.100.0",
    "constructs": "^10.3.0"
  },
  "devDependencies": {
    "@types/node": "^20.0.0",
    "typescript": "^5.0.0"
  }
}
```

---

## ðŸ—ï¸ Infrastructure Configuration

### 1. infra/infrastructure.ts (Core AWS Resources)

```typescript
import * as aws from "@pulumi/aws";
import { projectConfig, generateResourceName, generateBucketName } from "../project.config";

export function InfrastructureStack() {
  const stage = $app.stage;
  
  // Use existing VPC or create new one
  const vpcId = "vpc-xxxxxxxxxxxxx"; // Your VPC ID
  const vpc = aws.ec2.getVpc({ id: vpcId });
  const subnets = aws.ec2.getSubnets({
    filters: [{ name: "vpc-id", values: [vpcId] }],
  });

  // ðŸ—„ï¸ RDS PostgreSQL Database
  const dbSecurityGroup = new aws.ec2.SecurityGroup("DBSecurityGroup", {
    name: generateResourceName("db-sg", stage),
    vpcId: vpc.then(v => v.id),
    ingress: [
      {
        protocol: "tcp",
        fromPort: 5432,
        toPort: 5432,
        cidrBlocks: ["10.0.0.0/8"], // Restrict to your VPC CIDR
      },
    ],
    egress: [
      {
        protocol: "-1",
        fromPort: 0,
        toPort: 0,
        cidrBlocks: ["0.0.0.0/0"],
      },
    ],
    tags: { 
      Name: generateResourceName("db-sg", stage), 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  const dbSubnetGroup = new aws.rds.SubnetGroup("DBSubnetGroup", {
    name: generateResourceName("db-subnet-group", stage),
    subnetIds: subnets.then(s => s.ids),
    tags: { 
      Name: generateResourceName("db-subnet-group", stage), 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  const dbPassword = new aws.secretsmanager.Secret("DBPassword", {
    name: generateResourceName("db-password", stage),
    description: `RDS PostgreSQL password for ${stage}`,
    tags: { 
      Name: generateResourceName("db-password", stage), 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  const dbPasswordVersion = new aws.secretsmanager.SecretVersion("DBPasswordVersion", {
    secretId: dbPassword.id,
    secretString: $jsonStringify({
      password: $interpolate`${dbPassword.id}-generated`,
    }),
  });

  const database = new aws.rds.Instance("Database", {
    identifier: generateResourceName("db", stage),
    engine: projectConfig.resources.database.engine,
    engineVersion: projectConfig.resources.database.version,
    instanceClass: projectConfig.resources.database.instanceClass,
    allocatedStorage: projectConfig.resources.database.allocatedStorage,
    maxAllocatedStorage: projectConfig.resources.database.maxAllocatedStorage,
    dbSubnetGroupName: dbSubnetGroup.name,
    vpcSecurityGroupIds: [dbSecurityGroup.id],
    username: "admin_user",
    password: dbPasswordVersion.secretString.apply(s => JSON.parse(s).password),
    skipFinalSnapshot: stage !== "production",
    backupRetentionPeriod: projectConfig.resources.database.backupRetentionDays,
    publiclyAccessible: stage !== "production", // Set false for production
    multiAz: projectConfig.resources.database.multiAz,
    tags: { 
      Name: generateResourceName("db", stage), 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  // ðŸª£ S3 Bucket (using raw Pulumi for exact naming)
  const bucket = new aws.s3.BucketV2("DataBucket", {
    bucket: generateBucketName(stage),
    tags: { 
      Name: generateBucketName(stage), 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  const bucketVersioning = new aws.s3.BucketVersioningV2("BucketVersioning", {
    bucket: bucket.id,
    versioningConfiguration: {
      status: "Enabled",
    },
  });

  // ðŸ“¬ SQS Queue
  const processingQueue = new sst.aws.Queue("ProcessingQueue", {
    name: generateResourceName("processing-queue", stage),
    visibilityTimeout: projectConfig.resources.queue.visibilityTimeout,
    messageRetentionPeriod: projectConfig.resources.queue.messageRetentionPeriod,
  });

  // ðŸ“¬ Dead Letter Queue
  const deadLetterQueue = new sst.aws.Queue("DeadLetterQueue", {
    name: generateResourceName("dlq", stage),
    messageRetentionPeriod: "14 days",
  });

  // ðŸ”§ AWS Parameter Store for configuration
  const configParameter = new aws.ssm.Parameter("ConfigParameter", {
    name: `/${projectConfig.projectName}/${stage}/config`,
    type: "String",
    value: JSON.stringify({
      llm: {
        model: "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
        temperature: 0.1,
        top_p: 0.9,
        max_tokens: 4000,
      },
    }),
    tags: { 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  const businessRulesParameter = new aws.ssm.Parameter("BusinessRulesParameter", {
    name: `/${projectConfig.projectName}/${stage}/business-rules`,
    type: "String",
    value: JSON.stringify({
      // Your business rules configuration
    }),
    tags: { 
      Project: projectConfig.projectName, 
      Stage: stage 
    },
  });

  return {
    vpcId,
    database: {
      host: database.address,
      port: database.port,
      database: database.dbName,
      username: database.username,
      passwordSecretArn: dbPassword.arn,
      endpoint: database.endpoint,
      arn: database.arn,
    },
    bucket: {
      name: bucket.bucket,
      arn: bucket.arn,
    },
    processingQueue,
    deadLetterQueue,
    configParameter,
    businessRulesParameter,
  };
}
```

### 2. infra/application.ts (Lambda Functions & API)

```typescript
import { projectConfig, generateFunctionName } from "../project.config";

export function ApplicationStack(infrastructure: ReturnType<typeof import("./infrastructure").InfrastructureStack>) {
  const stage = $app.stage;

  // Get VPC subnets for Lambda
  const subnets = aws.ec2.getSubnets({
    filters: [{ name: "vpc-id", values: [infrastructure.vpcId] }],
  });

  // ðŸ Data Processor Lambda
  const dataProcessor = new sst.aws.Function("DataProcessor", {
    name: generateFunctionName("data-processor", stage),
    handler: "functions/src/handlers/data_processor.handler",
    runtime: projectConfig.resources.lambda.runtime,
    timeout: projectConfig.resources.lambda.timeout,
    memory: projectConfig.resources.lambda.memory,
    architecture: projectConfig.resources.lambda.architecture,
    environment: {
      ENVIRONMENT: stage,
      DB_HOST: infrastructure.database.host,
      DB_PORT: infrastructure.database.port.apply(p => p.toString()),
      DB_NAME: infrastructure.database.database,
      DB_USERNAME: infrastructure.database.username,
      DB_PASSWORD_SECRET_ARN: infrastructure.database.passwordSecretArn,
      S3_BUCKET_NAME: infrastructure.bucket.name,
      CONFIG_PARAMETER_NAME: infrastructure.configParameter.name,
      BUSINESS_RULES_PARAMETER_NAME: infrastructure.businessRulesParameter.name,
    },
    vpc: {
      securityGroups: [], // Add your security groups
      subnets: subnets.then(s => s.ids),
    },
    permissions: [
      {
        actions: ["rds-db:connect"],
        resources: [infrastructure.database.arn],
      },
      {
        actions: ["secretsmanager:GetSecretValue"],
        resources: [infrastructure.database.passwordSecretArn],
      },
      {
        actions: ["ssm:GetParameter", "ssm:GetParameters"],
        resources: [
          infrastructure.configParameter.arn,
          infrastructure.businessRulesParameter.arn,
        ],
      },
      {
        actions: ["s3:GetObject", "s3:PutObject", "s3:DeleteObject", "s3:ListBucket"],
        resources: [
          infrastructure.bucket.arn,
          infrastructure.bucket.arn.apply(arn => `${arn}/*`),
        ],
      },
    ],
  });

  // ðŸ¤– AI Processor Lambda
  const aiProcessor = new sst.aws.Function("AIProcessor", {
    name: generateFunctionName("ai-processor", stage),
    handler: "functions/src/handlers/ai_processor.handler",
    runtime: projectConfig.resources.lambda.runtime,
    timeout: projectConfig.resources.lambda.timeout,
    memory: projectConfig.resources.lambda.memory,
    architecture: projectConfig.resources.lambda.architecture,
    environment: {
      ENVIRONMENT: stage,
      S3_BUCKET_NAME: infrastructure.bucket.name,
      CONFIG_PARAMETER_NAME: infrastructure.configParameter.name,
      BUSINESS_RULES_PARAMETER_NAME: infrastructure.businessRulesParameter.name,
    },
    vpc: {
      securityGroups: [],
      subnets: subnets.then(s => s.ids),
    },
    permissions: [
      {
        actions: ["bedrock:InvokeModel", "bedrock:Converse"],
        resources: ["*"],
      },
      {
        actions: ["ssm:GetParameter", "ssm:GetParameters"],
        resources: [
          infrastructure.configParameter.arn,
          infrastructure.businessRulesParameter.arn,
        ],
      },
      {
        actions: ["s3:GetObject", "s3:PutObject", "s3:DeleteObject"],
        resources: [
          infrastructure.bucket.arn,
          infrastructure.bucket.arn.apply(arn => `${arn}/*`),
        ],
      },
    ],
  });

  // ðŸ“¬ SQS Trigger for AI Processor
  infrastructure.processingQueue.subscribe(aiProcessor.arn);

  // ðŸ”— API Gateway
  const api = new sst.aws.ApiGatewayV2("ProjectApi", {
    name: generateFunctionName("api", stage),
    cors: projectConfig.resources.api.cors,
    throttle: projectConfig.resources.api.throttle,
  });

  // ðŸ API Handler Lambda
  const apiHandler = new sst.aws.Function("ApiHandler", {
    name: generateFunctionName("api-handler", stage),
    handler: "functions/src/handlers/api_handler.handler",
    runtime: projectConfig.resources.lambda.runtime,
    timeout: "30 seconds",
    memory: "512 MB",
    architecture: projectConfig.resources.lambda.architecture,
    environment: {
      ENVIRONMENT: stage,
      S3_BUCKET_NAME: infrastructure.bucket.name,
      SQS_QUEUE_URL: infrastructure.processingQueue.url,
      DB_HOST: infrastructure.database.host,
      DB_PORT: infrastructure.database.port.apply(p => p.toString()),
    },
    vpc: {
      securityGroups: [],
      subnets: subnets.then(s => s.ids),
    },
    permissions: [
      {
        actions: ["sqs:SendMessage"],
        resources: [infrastructure.processingQueue.arn],
      },
      {
        actions: ["s3:GetObject", "s3:PutObject"],
        resources: [
          infrastructure.bucket.arn,
          infrastructure.bucket.arn.apply(arn => `${arn}/*`),
        ],
      },
    ],
  });

  // ðŸ”— API Routes
  api.route("GET /health", apiHandler.arn);
  api.route("POST /analyze", apiHandler.arn);
  api.route("GET /status/{id}", apiHandler.arn);

  return {
    api,
    apiHandler,
    dataProcessor,
    aiProcessor,
  };
}
```

---

## ðŸ Python Code Structure

### 1. functions/src/config/llm_config.py

```python
"""
LLM Configuration - Type definitions and model validation
Configuration values come from AWS Parameter Store
"""

from enum import Enum
from typing import List

class LLMModel(str, Enum):
    """AWS Bedrock LLM Model IDs"""
    CLAUDE_SONNET_4_5 = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"
    CLAUDE_3_5_SONNET = "us.anthropic.claude-3-5-sonnet-20241022-v2:0"
    CLAUDE_3_SONNET = "us.anthropic.claude-3-sonnet-20240229-v1:0"
    CLAUDE_3_HAIKU = "us.anthropic.claude-3-haiku-20240307-v1:0"
    NOVA_MICRO = "us.amazon.nova-micro-v1:0"
    NOVA_LITE = "us.amazon.nova-lite-v1:0"
    NOVA_PRO = "us.amazon.nova-pro-v1:0"

ALL_MODEL_IDS: List[str] = [model.value for model in LLMModel]

def validate_model_id(model_id: str) -> bool:
    """Validate if model ID is supported"""
    return model_id in ALL_MODEL_IDS

DEFAULT_MODEL = LLMModel.CLAUDE_SONNET_4_5

MODEL_ALIASES = {
    "claude": LLMModel.CLAUDE_SONNET_4_5,
    "sonnet": LLMModel.CLAUDE_SONNET_4_5,
    "claude-3.5": LLMModel.CLAUDE_3_5_SONNET,
    "haiku": LLMModel.CLAUDE_3_HAIKU,
    "fast": LLMModel.NOVA_MICRO,
    "balanced": LLMModel.NOVA_LITE,
    "powerful": LLMModel.NOVA_PRO,
}

def get_model_by_alias(alias: str) -> LLMModel:
    """Get model by alias name"""
    return MODEL_ALIASES.get(alias, DEFAULT_MODEL)
```

### 2. functions/src/config/aws_config.py

```python
"""
AWS Configuration Service - Fetches config from Parameter Store
"""

import os
import json
import boto3
import logging
from typing import Dict, Any, Optional
import time

logger = logging.getLogger(__name__)

class AWSConfigService:
    """Singleton service for AWS configuration management"""
    _instance = None
    _config_cache: Dict[str, Any] = {}
    _last_fetch_time: Optional[float] = None
    _cache_duration_seconds = 300  # Cache for 5 minutes

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(AWSConfigService, cls).__new__(cls)
            cls._instance._initialize()
        return cls._instance

    def _initialize(self):
        """Initialize AWS clients and configuration"""
        self.ssm_client = boto3.client('ssm', region_name=os.environ.get('AWS_REGION'))
        self.config_parameter_name = os.environ.get('CONFIG_PARAMETER_NAME')
        self.business_rules_parameter_name = os.environ.get('BUSINESS_RULES_PARAMETER_NAME')
        
        if not self.config_parameter_name or not self.business_rules_parameter_name:
            logger.warning("Parameter Store names not set in environment variables")

    def _should_refresh_cache(self) -> bool:
        """Check if cache should be refreshed"""
        if self._last_fetch_time is None:
            return True
        return (time.time() - self._last_fetch_time) > self._cache_duration_seconds

    def _fetch_config_from_ssm(self) -> Dict[str, Any]:
        """Fetch configuration from Parameter Store"""
        if not self._should_refresh_cache() and self._config_cache:
            return self._config_cache

        try:
            # Fetch both parameters
            response = self.ssm_client.get_parameters(
                Names=[
                    self.config_parameter_name,
                    self.business_rules_parameter_name,
                ],
                WithDecryption=True
            )

            config = {}
            for param in response.get('Parameters', []):
                if param['Name'] == self.config_parameter_name:
                    config['llm'] = json.loads(param['Value'])
                elif param['Name'] == self.business_rules_parameter_name:
                    config['business_rules'] = json.loads(param['Value'])

            self._config_cache = config
            self._last_fetch_time = time.time()
            logger.info("Successfully fetched configuration from Parameter Store")
            return config

        except Exception as e:
            logger.error(f"Error fetching config from Parameter Store: {e}")
            # Fall back to default config
            return self._get_default_config()

    def get_llm_config(self) -> Dict[str, Any]:
        """Get LLM configuration"""
        config = self._fetch_config_from_ssm()
        return config.get("llm", self._get_default_config().get("llm", {}))

    def get_business_rules(self, rule_type: str = None) -> Dict[str, Any]:
        """Get business rules configuration"""
        config = self._fetch_config_from_ssm()
        business_rules = config.get("business_rules", self._get_default_config().get("business_rules", {}))
        
        if rule_type:
            return business_rules.get(rule_type, {})
        return business_rules

    def _get_default_config(self) -> Dict[str, Any]:
        """Default configuration fallback"""
        return {
            "llm": {
                "model": "global.anthropic.claude-sonnet-4-5-20250929-v1:0",
                "temperature": 0.1,
                "top_p": 0.9,
                "max_tokens": 4000,
            },
            "business_rules": {
                # Your default business rules
            }
        }

# Convenience function
def get_aws_config() -> AWSConfigService:
    """Get AWS configuration service instance"""
    return AWSConfigService()
```

### 3. functions/src/services/bedrock_service.py

**âš ï¸ CRITICAL: Always use the Bedrock Converse API**

```python
"""
AWS Bedrock Service - ALWAYS uses Converse API
"""

import json
import logging
from typing import Dict, Any, Optional
import boto3
from botocore.exceptions import ClientError

from ..config.llm_config import LLMModel, validate_model_id, DEFAULT_MODEL
from ..config.aws_config import get_aws_config

logger = logging.getLogger(__name__)

class BedrockService:
    """Service for AWS Bedrock LLM interactions using Converse API"""
    
    def __init__(self, model: Optional[LLMModel] = None, region: str = "us-east-1"):
        """Initialize Bedrock service with configuration from Parameter Store"""
        aws_config = get_aws_config()
        llm_config = aws_config.get_llm_config()

        # Determine model to use
        if model:
            self.model = model
        else:
            model_id = llm_config.get("model", DEFAULT_MODEL.value)
            if validate_model_id(model_id):
                self.model = LLMModel(model_id)
            else:
                logger.warning(f"Invalid model ID {model_id}, using default")
                self.model = DEFAULT_MODEL

        self.bedrock_client = boto3.client('bedrock-runtime', region_name=region)
        self.llm_config = llm_config
        
        logger.info(f"Initialized BedrockService with model: {self.model.value}")
    
    def invoke_model(
        self, 
        prompt: str, 
        system_prompt: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Invoke model using Bedrock Converse API
        
        âš ï¸ CRITICAL: ALWAYS use converse() method, NOT invoke_model()
        
        Args:
            prompt: User prompt/message
            system_prompt: Optional system prompt
            **kwargs: Override inference parameters
            
        Returns:
            Dict containing response, usage metrics, and metadata
        """
        try:
            # Prepare messages for Converse API
            messages = [
                {
                    "role": "user",
                    "content": [{"text": prompt}]
                }
            ]
            
            # Add system prompt if provided
            system_config = []
            if system_prompt:
                system_config = [{"text": system_prompt}]
            
            # Create inference configuration from Parameter Store + overrides
            inference_config = {
                "maxTokens": kwargs.get("max_tokens", self.llm_config.get("max_tokens", 4000)),
                "temperature": kwargs.get("temperature", self.llm_config.get("temperature", 0.1)),
                "topP": kwargs.get("top_p", self.llm_config.get("top_p", 0.9)),
            }
            
            # âš ï¸ CRITICAL: Use converse() method
            response = self.bedrock_client.converse(
                modelId=self.model.value,
                messages=messages,
                system=system_config,
                inferenceConfig=inference_config
            )
            
            # Extract response content
            content = response['output']['message']['content'][0]['text']
            usage = response.get('usage', {})
            
            return {
                'success': True,
                'content': content,
                'usage': usage,
                'model': self.model.value,
                'metadata': {
                    'input_tokens': usage.get('inputTokens', 0),
                    'output_tokens': usage.get('outputTokens', 0),
                }
            }
            
        except ClientError as e:
            logger.error(f"Bedrock client error: {e}")
            return {
                'success': False,
                'error': str(e),
                'error_code': e.response.get('Error', {}).get('Code', 'Unknown'),
                'model': self.model.value,
            }
        except Exception as e:
            logger.error(f"Unexpected error in invoke_model: {e}")
            return {
                'success': False,
                'error': str(e),
                'model': self.model.value,
            }
```

---

## ðŸš¨ Common Issues and Resolutions

### Issue 1: UV + SST Lambda Packaging Failure

**Error:**
```
Error: failed to run uv build: exit status 2
Workspace does not contain any buildable packages
```

**Root Cause:**
The `functions/` directory lacks its own `pyproject.toml` file, which is REQUIRED by SST's UV integration.

**Resolution:**
1. Create `functions/pyproject.toml` with `hatchling` build backend (see configuration above)
2. Add `functions/__init__.py` to make it a proper package
3. Add `[tool.uv.workspace]` with `members = ["functions"]` to root `pyproject.toml`
4. **CRITICAL**: Explicitly list ALL packages including subdirectories in hatchling configuration

**Prevention:**
Always include both root and functions `pyproject.toml` files when using SST + UV.

### Issue 2: Top-Level Imports in sst.config.ts

**Error:**
```
Error: Your sst.config.ts has top level imports - this is not allowed.
```

**Root Cause:**
SST requires all imports to be dynamic (inside functions) to support different stages.

**Resolution:**
Change all top-level imports to dynamic imports:
```typescript
// âŒ BAD
import { projectConfig } from "./project.config";

// âœ… GOOD
async app(input) {
  const { projectConfig } = await import("./project.config");
}
```

### Issue 3: AssumeRole Permission Denied

**Error:**
```
User is not authorized to perform: sts:AssumeRole
```

**Root Cause:**
Trying to assume a cross-account role that doesn't exist or you don't have permission for.

**Resolution:**
If deploying to the same account, remove the `assumeRole` configuration from `sst.config.ts`:
```typescript
providers: {
  aws: {
    region: projectConfig.aws.region,
    profile: projectConfig.aws.profile,
    // Remove assumeRole if deploying to same account
  },
},
```

### Issue 4: Pulumi Pending Operations

**Error:**
```
warning: Attempting to deploy or update resources with 2 pending operations from previous deployment.
error: an unhandled error occurred: Program exited with non-zero exit code: -1
```

**Root Cause:**
Previous deployment was interrupted, leaving resources in an unknown state.

**Resolution:**
1. Check AWS Console to verify resource status
2. Run `pulumi refresh` interactively to clear pending state:
   ```bash
   npx sst shell --stage staging -- pulumi refresh
   ```
3. Manually delete stuck resources from AWS Console if necessary
4. Re-deploy after cleaning up state

### Issue 5: Invalid RDS PostgreSQL Version

**Error:**
```
InvalidParameterCombination: Cannot find version 15.4 for postgres
```

**Root Cause:**
The PostgreSQL version specified is not available in RDS.

**Resolution:**
Use a valid RDS PostgreSQL version. Check available versions:
```bash
aws rds describe-db-engine-versions \
  --engine postgres \
  --query 'DBEngineVersions[].EngineVersion' \
  --output table
```

Common valid versions: `16.4`, `15.8`, `14.13`, `13.16`

### Issue 6: S3 Bucket Naming Issues

**Error:**
Bucket name includes unexpected suffixes like `bucket-edootcua`

**Root Cause:**
SST automatically generates unique suffixes for certain resource types.

**Resolution:**
Use raw Pulumi `aws.s3.BucketV2` instead of `sst.aws.Bucket` for exact control:
```typescript
const bucket = new aws.s3.BucketV2("DataBucket", {
  bucket: generateBucketName(stage), // Exact name you want
  tags: { Name: generateBucketName(stage) },
});
```

### Issue 7: Large Dependencies in Root pyproject.toml

**Error:**
Slow UV syncs, large Lambda packages, timeouts during deployment

**Root Cause:**
Root `pyproject.toml` includes unnecessary packages like `streamlit`, `jupyterlab`, `scikit-learn`.

**Resolution:**
Keep root dependencies minimal - only what's needed for local dev/scripts:
```toml
dependencies = [
    "boto3>=1.40.44",
    "botocore>=1.40.44",
    "pydantic>=2.11.9",
    "pandas>=2.2.2",
    "psycopg2-binary>=2.9.10",
    "sqlalchemy>=2.0.40",
]
```

Remove all UI frameworks, ML libraries, and development tools unless absolutely necessary.

### Issue 8: Missing .python-version File

**Error:**
UV uses wrong Python version, package compatibility issues

**Resolution:**
Create `.python-version` in both root and `functions/` directories:
```
3.12.10
```

### Issue 9: VPC Lambda Cannot Access RDS

**Error:**
Lambda times out connecting to RDS

**Root Cause:**
Security group rules not configured properly, or Lambda not in correct subnets.

**Resolution:**
1. Ensure Lambda is in same VPC as RDS
2. Configure security group to allow ingress from Lambda security group
3. Ensure Lambda has NAT Gateway or VPC endpoints for AWS services
4. Check RDS security group allows port 5432 from Lambda subnet CIDR

---

## ðŸš€ Deployment Process

### Pre-Deployment Script

Create `scripts/pre-deploy.sh`:

```bash
#!/bin/bash
# Pre-deployment cleanup and verification

set -e

echo "ðŸ§¹ Running pre-deployment cleanup..."

# Clean UV artifacts
echo "Cleaning UV build artifacts..."
find functions -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true
find functions -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
find functions -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true

# Verify critical files exist
echo "âœ“ Verifying critical files..."
if [ ! -f "functions/pyproject.toml" ]; then
    echo "âŒ ERROR: functions/pyproject.toml is missing!"
    exit 1
fi

if [ ! -f "functions/__init__.py" ]; then
    echo "âŒ ERROR: functions/__init__.py is missing!"
    exit 1
fi

if [ ! -f "pyproject.toml" ]; then
    echo "âŒ ERROR: Root pyproject.toml is missing!"
    exit 1
fi

# Check for workspace configuration
if ! grep -q "\[tool.uv.workspace\]" pyproject.toml; then
    echo "âŒ ERROR: Root pyproject.toml missing [tool.uv.workspace] section!"
    exit 1
fi

echo "âœ“ All critical files present"

# Regenerate lock files
echo "ðŸ”„ Regenerating UV lock files..."
cd "$(dirname "$0")/.."
uv lock
cd functions
uv lock
cd ..

# Test UV export
echo "ðŸ§ª Testing UV export..."
cd functions
if ! uv export --format requirements-txt > /dev/null; then
    echo "âŒ ERROR: UV export failed!"
    exit 1
fi
cd ..

echo "âœ… Pre-deployment checks complete!"
```

### Deployment Script

Create `scripts/deploy.sh`:

```bash
#!/bin/bash
# Main deployment script

set -e

STAGE=${1:-staging}

echo "ðŸš€ Deploying to stage: $STAGE"

# Run pre-deployment checks
./scripts/pre-deploy.sh

# Clear SST cache (optional, if experiencing issues)
# rm -rf .sst/platform/dist

# Deploy
echo "ðŸ“¦ Starting SST deployment..."
npx sst deploy --stage "$STAGE"

echo "âœ… Deployment complete!"
```

### Step-by-Step Deployment

1. **Initial Setup:**
   ```bash
   npm install
   uv sync
   ```

2. **Run Pre-Deployment Checks:**
   ```bash
   chmod +x scripts/pre-deploy.sh scripts/deploy.sh
   ./scripts/pre-deploy.sh
   ```

3. **Deploy to Staging:**
   ```bash
   ./scripts/deploy.sh staging
   ```

4. **Verify Deployment:**
   ```bash
   # Check API Gateway endpoint
   curl https://your-api-id.execute-api.us-east-1.amazonaws.com/health
   
   # View logs
   npm run logs
   ```

5. **Deploy to Production (when ready):**
   ```bash
   ./scripts/deploy.sh production
   ```

---

## ðŸ“Š Best Practices

### 1. Resource Naming

**âš ï¸ CRITICAL: SST Auto-Generated Suffixes**

SST automatically adds unique suffixes to certain resource types for CloudFormation compatibility. This is **BY DESIGN** and cannot be avoided when using SST components.

**Resources with SST-generated suffixes:**
- **SQS Queues**: `sst.aws.Queue` adds suffix like `-knxrctce`
  - Example: `DAW-ai-patient-ranking-staging-AIProcessingQueueQueue-knxrctce`
- **API Gateway**: `sst.aws.ApiGatewayV2` adds suffix like `-watnmwfh`
  - Example: `DAW-ai-patient-ranking-staging-ApiApi-watnmwfh`
- **CloudWatch Log Groups**: Auto-generated by SST

**Resources with exact naming (using raw Pulumi):**
- **S3 Buckets**: Use `aws.s3.BucketV2` for exact names
  - Example: `DAW-ai-patient-ranking-staging`
- **RDS Databases**: Use `aws.rds.Instance` for exact names
- **Parameter Store**: Use `aws.ssm.Parameter` for exact names
- **Secrets Manager**: Use `aws.secretsmanager.Secret` for exact names
- **Lambda Functions**: SST respects the `name` parameter

**To get exact resource names:**
1. Use raw Pulumi resources (`aws.*`) instead of SST components (`sst.aws.*`)
2. Accept SST's naming for convenience features (queues, API Gateway)
3. Reference resources by ARN/ID in code, not by name

**Example - Exact naming with raw Pulumi:**
```typescript
// âœ… Exact S3 bucket name
const bucket = new aws.s3.BucketV2("DataBucket", {
  bucket: `${projectName}-${stage}`, // Exact name
});

// âŒ SST adds suffix
const queue = new sst.aws.Queue("ProcessingQueue", {
  name: "my-queue", // Becomes: my-queue-xyz123abc
});

// âœ… Use raw Pulumi for exact SQS name (but lose SST conveniences)
const queue = new aws.sqs.Queue("ProcessingQueue", {
  name: `${projectName}-queue-${stage}`, // Exact name
});
```

**Best Practices:**
- Use consistent naming: `project-name-resource-type-stage`
- Accept SST suffixes for convenience features
- Use raw Pulumi when exact names are critical
- Reference resources by ARN/URL in application code
- Document naming conventions in `project.config.ts`

### 2. Configuration Management
- Store all secrets in AWS Secrets Manager
- Store all configuration in AWS Parameter Store
- Never hardcode credentials or sensitive data
- Use environment-specific configuration

### 3. Security
- Use least-privilege IAM policies
- Enable VPC for RDS and Lambda (production)
- Use security groups with specific IP ranges
- Enable encryption at rest and in transit
- Enable deletion protection for production databases

### 4. Cost Optimization
- Use appropriate Lambda memory settings
- Implement caching where possible
- Use Parameter Store caching (5 minutes)
- Monitor Bedrock token usage
- Set appropriate log retention periods

### 5. Monitoring
- Use structured JSON logging
- Implement CloudWatch dashboards
- Set up CloudWatch alarms for errors
- Track token usage and costs
- Monitor Lambda duration and errors

### 6. Testing
- Write unit tests for business logic
- Create integration tests for API endpoints
- Test Lambda functions locally with `sst dev`
- Validate database migrations before production
- Test rollback procedures

---

## ðŸ” Troubleshooting Checklist

When deployment fails:

1. ðŸš¨ **CHECK PULUMI LOGS FIRST**: `grep -i "error\|fail\|exception" .sst/pulumi/*/eventlog.json` - This saves 20+ minutes of troubleshooting
2. âœ… **For state sync issues**: Use `sst refresh --stage dev` (NOT `sst remove`)
3. âœ… Check `functions/pyproject.toml` exists and uses `hatchling` with explicit packages
4. âœ… Verify root `pyproject.toml` has `[tool.uv.workspace]` section
5. âœ… Confirm no top-level imports in `sst.config.ts`
6. âœ… Check all dynamic imports use `await import()`
7. âœ… Verify AWS credentials are configured correctly
8. âœ… Check IAM permissions for Bedrock, S3, RDS, Lambda
8. âœ… Verify VPC and security group configurations
9. âœ… **NEVER manually update AWS resources** - use SST config only
10. âœ… **NEVER delete .venv** - it's UV managed
8. âœ… Check CloudWatch logs for Lambda errors
9. âœ… Verify Parameter Store parameters exist and are accessible
10. âœ… Check for Pulumi pending operations
11. âœ… Verify RDS PostgreSQL version is valid
12. âœ… Check S3 bucket naming doesn't conflict
13. âœ… Verify Python version matches `.python-version` files
14. âœ… Run `./scripts/pre-deploy.sh` to validate setup

### ðŸš¨ **If you see "No module named 'core'" errors:**

1. âœ… **Check SST handler path configuration**:
   ```typescript
   // In infra/application.ts
   handler: "functions/src/handlers/your_handler.handler"
   ```

2. âœ… **Check import paths in handler code**:
   ```python
   # Use functions.src.* imports
   from functions.src.core.protocols import GapDetails
   from functions.src.services.database_service import DatabaseService
   ```

3. âœ… **Verify hatchling configuration** (should be simple):
   ```toml
   [tool.hatch.build.targets.wheel]
   packages = ["src"]  # âœ… This is sufficient
   ```

4. âœ… **Remove SST state and deploy fresh**:
   ```bash
   rm -rf .sst
   npx sst deploy --stage dev
   ```

3. âœ… **Verify wheel contents locally**:
   ```bash
   cd functions && uv build
   python -c "import zipfile; print([f for f in zipfile.ZipFile('dist/functions-1.0.0-py3-none-any.whl').namelist() if 'core' in f])"
   ```

4. âœ… **Check health endpoint** - should show no "No module named" errors

---

## ðŸ“š Additional Resources

- [SST Documentation](https://docs.sst.dev/)
- [AWS Bedrock Documentation](https://docs.aws.amazon.com/bedrock/)
- [Bedrock Converse API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_runtime_Converse.html)
- [UV Documentation](https://docs.astral.sh/uv/)
- [AWS Lambda Best Practices](https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html)
- [RDS PostgreSQL Versions](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html)

---

## ðŸŽ¯ Summary

This guide provides a complete, battle-tested approach to migrating Python + AWS Bedrock applications to serverless architecture using SST. The key success factors are:

1. **Proper UV workspace configuration** with both root and functions `pyproject.toml`
2. **Dynamic imports** in SST configuration files
3. **Always using Bedrock Converse API** for LLM calls
4. **Parameter Store** for all configuration management
5. **Minimal dependencies** in root pyproject.toml
6. **Pre-deployment validation** scripts
7. **Understanding common issues** and their resolutions
8. **VPC endpoints for AWS services** to avoid NAT Gateway costs
9. **Lambda Layers for shared dependencies** to optimize package sizes
10. **Secure database access patterns** for private resources

## ðŸš€ **NEXT STEPS FOR PRODUCTION**

After completing the migration using this guide, consider these production enhancements:

### **Performance Optimization**
- **CloudWatch monitoring** with custom metrics for AI processing times
- **Lambda provisioned concurrency** for consistent response times
- **RDS connection pooling** with RDS Proxy for high concurrency
- **S3 Transfer Acceleration** for large file uploads

### **Security Hardening**
- **WAF (Web Application Firewall)** on API Gateway
- **Secrets rotation** automation for database credentials
- **VPC Flow Logs** for network monitoring
- **IAM least-privilege policies** review and refinement

### **Scalability Enhancements**
- **Auto-scaling policies** for Lambda concurrency limits
- **Multi-AZ RDS deployment** for high availability
- **CloudFront CDN** for API caching and global distribution
- **SQS DLQ (Dead Letter Queue)** for failed message handling

### **CI/CD Pipeline**
- **GitHub Actions or AWS CodePipeline** for automated deployments
- **Environment-specific configurations** (dev/staging/prod)
- **Automated testing** with Lambda test events
- **Blue-green deployments** for zero-downtime updates

### **Monitoring & Alerting**
- **CloudWatch dashboards** for operational metrics
- **SNS notifications** for system alerts
- **X-Ray tracing** for distributed application debugging
- **Cost monitoring** with AWS Budgets and Cost Explorer

Follow this guide exactly, and your migration should be smooth and successful. When in doubt, refer to the "CRITICAL ISSUES & SOLUTIONS" section for specific error messages and their fixes.

---

**Last Updated:** 2025-10-14  
**Version:** 3.0.0 - Generic SST Migration Playbook  
**Tested With:** SST 3.17.14, UV 0.5+, Python 3.12, Node.js 24.5.0  
**Production Ready:** âœ… Complete serverless architecture with enterprise security

